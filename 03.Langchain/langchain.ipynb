{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Langchain\n",
    "\n",
    "In this lab, we will introduce [Langchain](https://python.langchain.com/docs/get_started/introduction), a framework for developing applications powered by language models.\n",
    "\n",
    "Langchain supports Python and Javascript / Typescript. For this lab, we will use Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the `AzureOpenAI` specific components from the `langchain` package, including models and schemas for interacting with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.39 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-openai) (0.3.39)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-openai) (1.64.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.3.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\piotrbubacz\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.39->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\piotrbubacz\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with all the other labs, we'll need to provide our API key and endpoint details, so we'll load them from our `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI Endpoint: https://aoi-sec.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"No file .env found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll configure Langchain by providing the Azure OpenAI deployment name. Langchain will automatically retrieve details for the Azure OpenAI endpoint and version from the environment variables we've set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using Langchain\n",
    "\n",
    "We're now ready to send a request to Azure OpenAI. To do this, we invoke the `llm` instance we created above and pass in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raspberry Pi is an incredibly versatile platform that can be used for a wide variety of projects. Here are some ideas for things you could make with a Raspberry Pi:\n",
      "\n",
      "1. **Media Center**: Use software like Kodi or Plex to turn your Raspberry Pi into a home media center.\n",
      "\n",
      "2. **Retro Gaming Console**: Set up RetroPie or Recalbox to emulate classic gaming consoles and play retro games.\n",
      "\n",
      "3. **Home Automation Hub**: Create a smart home system using platforms like Home Assistant or OpenHAB to control lights, thermostats, and other smart devices.\n",
      "\n",
      "4. **Web Server**: Host a personal website or blog using software like Apache or Nginx.\n",
      "\n",
      "5. **Pi-Hole**: Create a network-wide ad blocker that filters advertisements at the DNS level.\n",
      "\n",
      "6. **Network Attached Storage (NAS)**: Set up your Raspberry Pi as a file server for shared storage.\n",
      "\n",
      "7. **Personal Cloud Storage**: Use Nextcloud or ownCloud to set up your own cloud storage solution.\n",
      "\n",
      "8. **Security Camera System**: Build a home security system with cameras, motion detection, and notifications using software like MotionEyeOS.\n",
      "\n",
      "9. **Weather Station**: Collect and display weather data using sensors connected to your Raspberry Pi.\n",
      "\n",
      "10. **VPN Server**: Set up a Virtual Private Network for secure browsing.\n",
      "\n",
      "11. **Digital Photo Frame**: Display a slideshow of your favorite photos on a connected display.\n",
      "\n",
      "12. **Smart Mirror**: Build a smart mirror that can display time, weather, calendar events, and news.\n",
      "\n",
      "13. **Voice Assistant**: Create your own voice-controlled assistant using platforms like Mycroft.\n",
      "\n",
      "14. **IoT Projects**: Connect sensors and actuators to create Internet of Things projects for monitoring and automation.\n",
      "\n",
      "15. **Learning Platform**: Use it to learn programming languages like Python, Java, or others.\n",
      "\n",
      "16. **Game Server**: Set up a multiplayer game server for games like Minecraft or Counter-Strike.\n",
      "\n",
      "17. **Home Theater PC (HTPC)**: Stream movies and shows, or use it for online gaming.\n",
      "\n",
      "18. **FloraPi**: Build a plant care system that monitors moisture, light, and temperature.\n",
      "\n",
      "19. **Robotics Projects**: Use it as a brain for robotics projects, controlling motors and sensors.\n",
      "\n",
      "20. **Social Media Bot**: Create scripts to automate posts or gather data from social media platforms.\n",
      "\n",
      "21. **Digital Assistant Dashboard**: Build a custom dashboard that integrates various services and displays information.\n",
      "\n",
      "These are just a few examples; the possibilities are nearly limitless, and each project can be customized to fit your needs and interests.\n"
     ]
    }
   ],
   "source": [
    "r = llm.invoke(\"What things could I make with a Raspberry Pi?\")\n",
    "\n",
    "# Print the response\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to using the OpenAI Python library as we did in the previous lab, Langchain further simplified the process of interacting with the LLM by reducing it to a `llm.invoke` call."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using templates and chains\n",
    "\n",
    "We've seen that we can use Langchain to interact with the LLM and it's a little easier to work with than the OpenAI Python library. However, that's just the start of how Langchain makes it easier to work with LLM's. Most OpenAI models are designed to be interacted with using a Chat style interface, where you provide a persona or system prompt which helps the LLM understand the context of the conversation. This will then be sent to the LLM along with the user's request.\n",
    "\n",
    "So that you don't have to setup the persona / system prompt every time you want to interact with the LLM, Langchain provides the concept of Templates. Templates are a way to define the persona and system prompt once and then reuse them across multiple interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a chatbot that helps people generate ideas for their next project. You can help them brainstorm ideas, come up with a plan, or even help them with their project.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we've defined a \"system\" message which will tell the LLM how we're expecting it to respond, and an `{input}` placeholder for the user's prompt.\n",
    "\n",
    "Next, we define a chain. A chain allows us to define a sequence of operations that we want to perform. In this case, we're defining a simple chain that will take the prompt we've defined above and send it to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can invoke the chain in a similar fashion to how to invoked the LLM earlier. This time, we're passing in the user's input as a parameter to the chain, which will replace the `{input}` placeholder in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"I've just purchased a Raspberry Pi and I'm looking for a project to work on. Can you help me brainstorm some ideas?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will be an `AIMessage` object, which contains the response from the LLM.\n",
    "\n",
    "Let's enhance the chain further to get it to parse the output from the LLM and extract the text from the response. First, we define an output parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we redefine our chain to include the output parser. So now when we invoke the chain, it will \n",
    "\n",
    "- Take the prompt template and add the user's input\n",
    "- Send the prompt to the LLM\n",
    "- Parse the response from the LLM and extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's invoke the chain again with the same prompt as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"I've just purchased a Raspberry Pi and I'm looking for a project to work on. Can you help me brainstorm some ideas?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, you should only get a string containing the text from the response.\n",
    "\n",
    "We can do much more powerful things with chains than simply setting up and passing prompts to the LLM and parsing the results. We can augment the prompt with external data retrieved from a database, we could add conversation history to provide context for a chatbot, or we could even chain multiple LLMs together to create a more powerful model. We'll explore some of these ideas in future labs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Langchain is an example of an AI orchestrator. It provides an alternative method to the raw API or using an SDK package to access the AI models, but on top of that can provide additional integrations, deal with issues related to rate limiting of the API and provide an abstraction layer over potentially complex operations. We'll get into those more complex use cases in later labs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we'll look at practical use of API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [Prompt Engineering](../04.Prompts/prompts.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
