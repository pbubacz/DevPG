{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = \"2024-06-01\" #os.getenv(\"OPENAI_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity \n",
    "Cosine similarity is a metric used to measure how similar two vectors are, regardless of their magnitude. It is commonly used in the context of embeddings, which are representations of data points in a high-dimensional space, such as word embeddings in natural language processing.\n",
    "\n",
    "### Key Points about Cosine Similarity:\n",
    "\n",
    "1. **Definition**:\n",
    "   Cosine similarity calculates the cosine of the angle between two vectors. The formula is:\n",
    "   $$\n",
    "   \\text{cosine similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|}\n",
    "   $$\n",
    "   where \\( \\mathbf{A} \\cdot \\mathbf{B} \\) is the dot product of vectors \\( \\mathbf{A} \\) and \\( \\mathbf{B} \\), and \\( \\|\\mathbf{A}\\| \\) and \\( \\|\\mathbf{B}\\| \\) are the magnitudes (or norms) of the vectors.\n",
    "\n",
    "2. **Range**:\n",
    "   The cosine similarity value ranges from -1 to 1:\n",
    "   - **1** indicates that the vectors are identical.\n",
    "   - **0** indicates that the vectors are orthogonal (no similarity).\n",
    "   - **-1** indicates that the vectors are diametrically opposed.\n",
    "\n",
    "3. **Applications**:\n",
    "   - **Text Analysis**: Used to compare the similarity between documents or sentences.\n",
    "   - **Recommendation Systems**: Helps in finding similar items or users based on their embeddings.\n",
    "   - **Image Recognition**: Used to compare feature vectors of images.\n",
    "\n",
    "4. **Advantages**:\n",
    "   - **Scale-Invariant**: Cosine similarity is unaffected by the magnitude of the vectors, making it useful for comparing normalized data.\n",
    "   - **Efficient**: Computationally efficient for high-dimensional data.\n",
    "\n",
    "5. **Example**:\n",
    "   Suppose we have two word embeddings \\( \\mathbf{A} \\) and \\( \\mathbf{B} \\):\n",
    "   $$\n",
    "   \\mathbf{A} = [1, 2, 3], \\quad \\mathbf{B} = [4, 5, 6]\n",
    "   $$\n",
    "   The cosine similarity is calculated as:\n",
    "   $$\n",
    "   \\text{cosine similarity} = \\frac{(1 \\cdot 4 + 2 \\cdot 5 + 3 \\cdot 6)}{\\sqrt{1^2 + 2^2 + 3^2} \\cdot \\sqrt{4^2 + 5^2 + 6^2}} = \\frac{32}{\\sqrt{14} \\cdot \\sqrt{77}} \\approx 0.974\n",
    "   $$\n",
    "\n",
    "Cosine similarity is a powerful tool for measuring similarity in various applications, especially when dealing with high-dimensional data like embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings calculation for the ada model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = 'the quick brown fox jumped over the lazy dog'\n",
    "model = 'text-embedding-ada-002'\n",
    "try:\n",
    "    text_embedding_ada=client.embeddings.create(input = [text], model=model, dimensions=1536).data[0].embedding\n",
    "except Exception as e:\n",
    "    text_embedding_ada=client.embeddings.create(input = [text], model=model,).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_embedding_ada[:10])\n",
    "print(len(text_embedding_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word comparision using embeddings and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare several words\n",
    "automobile_embedding_ada    = client.embeddings.create(input = 'automobile', model=model).data[0].embedding\n",
    "vehicle_embedding_ada       = client.embeddings.create(input = 'vehicle', model=model).data[0].embedding\n",
    "dinosaur_embedding_ada      = client.embeddings.create(input = 'dinosaur', model=model).data[0].embedding\n",
    "stick_embedding_ada         = client.embeddings.create(input = 'stick', model=model).data[0].embedding\n",
    "huskey_embedding_ada        = client.embeddings.create(input = 'huskey', model=model).data[0].embedding\n",
    "brown_embedding_ada         = client.embeddings.create(input = 'brown fox', model=model).data[0].embedding\n",
    "\n",
    "# comparing cosine similarity, automobiles vs automobiles should be 1.0, i.e exactly the same, while automobiles vs dinosaurs should be between 0 and 1, i.e. not the same\n",
    "print(cosine_similarity(automobile_embedding_ada, automobile_embedding_ada))\n",
    "print(cosine_similarity(automobile_embedding_ada, vehicle_embedding_ada))\n",
    "print(cosine_similarity(automobile_embedding_ada, dinosaur_embedding_ada))\n",
    "print(cosine_similarity(automobile_embedding_ada, stick_embedding_ada))\n",
    "print(cosine_similarity(automobile_embedding_ada, huskey_embedding_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same check for large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'the quick brown fox jumped over the lazy dog'\n",
    "model = 'text-embedding-3-large'\n",
    "\n",
    "text_embedding= client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare several words\n",
    "automobile_embedding    = client.embeddings.create(input = 'automobile', model=model).data[0].embedding\n",
    "vehicle_embedding       = client.embeddings.create(input = 'vehicle', model=model).data[0].embedding\n",
    "dinosaur_embedding      = client.embeddings.create(input = 'dinosaur', model=model).data[0].embedding\n",
    "stick_embedding         = client.embeddings.create(input = 'stick', model=model).data[0].embedding\n",
    "huskey_embedding        = client.embeddings.create(input = 'huskey', model=model).data[0].embedding\n",
    "brown_embedding         = client.embeddings.create(input = 'brown fox', model=model).data[0].embedding\n",
    "\n",
    "\n",
    "# comparing cosine similarity, automobiles vs automobiles should be 1.0, i.e exactly the same, while automobiles vs dinosaurs should be between 0 and 1, i.e. not the same\n",
    "print(cosine_similarity(automobile_embedding, automobile_embedding))\n",
    "print(cosine_similarity(automobile_embedding, vehicle_embedding))\n",
    "print(cosine_similarity(automobile_embedding, dinosaur_embedding))\n",
    "print(cosine_similarity(automobile_embedding, stick_embedding))\n",
    "print(cosine_similarity(automobile_embedding, huskey_embedding))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
