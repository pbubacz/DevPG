{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Using the OpenAI Library\n",
    "\n",
    "In the [first](../01.API/azureopenaiapi.ipynb) lab, we walked through calling the Azure OpenAI API directly to submit a prompt for completion. An easier way to work with an API is to use a *Library*. A Library is a collection of packages and modules that allow reusable code to be shared with the community.\n",
    "\n",
    "In this lab, we'll use the OpenAI Python library to perform the same operations as we did in the first lab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the `import` statement to let our application know that we're going to be using the OpenAI library in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.64.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\piotrbubacz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\piotrbubacz\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll start to bring in the values from our `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://aoi-sec.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a new `AzureOpenAI` object and pass in the API key and version and the endpoint URL to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the OpenAI library\n",
    "\n",
    "Now that we have defined an Azure OpenAI instance, let's try a Chat Completion. We'll call the `chat.completions.create()` method. Note that for the `model` value, we actually pass in the id of our Azure OpenAI `deployment`. We'll also pass the `prompt` we want to use as the `content` of the `messages` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BKieknpRZjkKJlTig5kPd9EDDNeYW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"It sounds like you have a deep passion for something special! What is that one thing you love more than anything else? I'd love to hear about it!\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1744277918, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_ded0d14823', usage=CompletionUsage(completion_tokens=32, prompt_tokens=18, total_tokens=50, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"),\n",
    "    messages = [{\"role\" : \"user\", \"content\" : \"The one thing I love more than anything else is \"}],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response above should be similar JSON data to what we got when we called the API directly in the previous exercise, containing details of the model we called, the response that was generated and the token usage.\n",
    "\n",
    "We can use the structured response returned by the API to just extract the generated response text on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like you have a deep passion for something special! What is that one thing you love more than anything else? I'd love to hear about it!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will print the response text in the same way as we did in the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-BKieknpRZjkKJlTig5kPd9EDDNeYW\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"It sounds like you have a deep passion for something special! What is that one thing you love more than anything else? I'd love to hear about it!\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            },\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1744277918,\n",
      "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": null,\n",
      "    \"system_fingerprint\": \"fp_ded0d14823\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 32,\n",
      "        \"prompt_tokens\": 18,\n",
      "        \"total_tokens\": 50,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    },\n",
      "    \"prompt_filter_results\": [\n",
      "        {\n",
      "            \"prompt_index\": 0,\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"jailbreak\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "response_json = json.loads(response.model_dump_json())\n",
    "print(json.dumps(response_json, indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The OpenAI library provides a more concise way to work with the OpenAI API. Once we've set up the initial parameters, we don't need to send them each time as we need to do with a direct API call. It's also easier to add information such as prompts to the call, as we can pass those values in as part of the call to the OpenAI library methods instead of having to pass in JSON objects as part of the request body.\n",
    "\n",
    "You can find more details about the completions API in the reference documentation:\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab we'll begin looking at AI orchestrators. Whereas the OpenAI library simplfies working with the OpenAI API, orchestrators take things to the next level!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "📣 [Langchain](../03.Langchain/langchain.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
